{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a7a6f5",
   "metadata": {},
   "source": [
    "# Fine-Tuning T5 Small for Error Explanations in Google Colab\n",
    "\n",
    "This notebook demonstrates how to fine-tune the Google T5 Small (60M parameters) model to generate structured error explanations in a universal format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92157bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Required Libraries\n",
    "!pip install transformers torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0793cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d972f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the T5 Small Model and Tokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the Training Dataset\n",
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "# Upload the JSON file to Colab or place it in your Drive\n",
    "# For example, if uploaded: data_path = '/content/error_explanations_dataset.json'\n",
    "# If in Drive: data_path = '/content/drive/MyDrive/error_explanations_dataset.json'\n",
    "data_path = '/content/error_explanations_dataset.json'  # Change this path as needed\n",
    "\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [\"explain error: \" + ex for ex in examples[\"input\"]]\n",
    "    targets = examples[\"output\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "tokenized_datasets.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a17720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Training Configuration\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,  # Small batch size for Colab\n",
    "    num_train_epochs=5,  # More epochs since dataset is small\n",
    "    weight_decay=0.01,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37241876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-Tune the Model\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"/content/drive/MyDrive/t5_error_explainer\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/t5_error_explainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Fine-Tuned Model\n",
    "input_text = \"explain error: IndentationError: unexpected indent in Python\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids, max_length=1024, num_beams=4, early_stopping=True)\n",
    "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(decoded)\n",
    "\n",
    "# Instructions for using the model\n",
    "print(\"\\nTo use this model in your code:\")\n",
    "print(\"from transformers import T5Tokenizer, T5ForConditionalGeneration\")\n",
    "print(\"tokenizer = T5Tokenizer.from_pretrained('/content/drive/MyDrive/t5_error_explainer')\")\n",
    "print(\"model = T5ForConditionalGeneration.from_pretrained('/content/drive/MyDrive/t5_error_explainer')\")\n",
    "print(\"input_text = 'explain error: <your error message>'\")\n",
    "print(\"input_ids = tokenizer.encode(input_text, return_tensors='pt')\")\n",
    "print(\"outputs = model.generate(input_ids, max_length=1024, num_beams=4, early_stopping=True)\")\n",
    "print(\"explanation = tokenizer.decode(outputs[0], skip_special_tokens=True)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
