{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15560dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "# Install Transformers.js if not already installed\n",
    "# Note: In Colab, you might need to use a different approach\n",
    "# For local development in VS Code, use npm install @xenova/transformers\n",
    "\n",
    "# For Colab environment, you can use:\n",
    "# !pip install transformers torch\n",
    "# But for client-side, use Transformers.js\n",
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3473ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1dcc58802a4a6491d0b3f4e0fc3863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6293b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for using Gemma model with Transformers.js\n",
    "# This would run in a browser or Node.js environment\n",
    "\n",
    "import { pipeline } from '@xenova/transformers';\n",
    "\n",
    "// Load the model\n",
    "const generator = await pipeline('text-generation', 'Xenova/functiongemma-270m-it');\n",
    "\n",
    "// Example prompt for educational feedback\n",
    "const prompt = `You are an educational programming tutor.\n",
    "\n",
    "Program output:\n",
    "error: expected ';' before '}' token\n",
    "\n",
    "Explain this error:`;\n",
    "\n",
    "// Generate response\n",
    "const output = await generator(prompt, {\n",
    "    max_new_tokens: 200,\n",
    "    temperature: 0.7,\n",
    "});\n",
    "\n",
    "console.log(output[0].generated_text);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54debf52",
   "metadata": {},
   "source": [
    "## Download Gemma 270M locally via Colab\n",
    "\n",
    "1. Make sure you are logged in (`login()` cell).\n",
    "\n",
    "2. Accept the model terms at https://huggingface.co/google/functiongemma-270m-it.\n",
    "\n",
    "3. Run the next cell to download tokenizer + weights into `/content/functiongemma-270m-it`.\n",
    "\n",
    "4. Zip and download that folder to your machine; point Transformers.js to the local path.\n",
    "\n",
    "5. Set `GEMMA_MODEL_DIR` in your extension host environment to that local folder path (or keep using HF + `HUGGING_FACE_HUB_TOKEN`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c374b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efa39f52d3e4543bccb18847962428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bf0493923147f48e8b9b89b81189c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/13.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6823e3e33964d1f9fd5b54954280eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/63.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1908886de6904010b44b7d2b5ac56b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/176 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148082c078614baeb064bc24ca6503b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5e02c538234ddca0a33bbcb2355a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/21.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7790f63f974205843d60d0a1fc4f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0768f9f06248efa9a70cc9edc0349e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b04f8bbc477488ba38fdaa53fd355db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d9bf2f0d604492accb3b5f5e86a1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tiny_garden.litertlm:   0%|          | 0.00/288M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17bf12571c849d4adf072c93263b0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ccdfa7aa124138bde8955f0bce6647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bea7643434f9480ea4e1ed2ea7ef54cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /content/functiongemma-270m-it\n",
      "Zip and download this folder, then point Transformers.js to it.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set your token here if login() is not working in this session\n",
    "HF_TOKEN = os.environ.get(\"HUGGING_FACE_HUB_TOKEN\", \"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\")\n",
    "\n",
    "# Downloads the entire repo (tokenizer + weights) to /content/functiongemma-270m-it\n",
    "local_dir = \"/content/functiongemma-270m-it\"\n",
    "if os.path.exists(local_dir):\n",
    "    shutil.rmtree(local_dir)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"google/functiongemma-270m-it\",\n",
    "    local_dir=local_dir,\n",
    "    token=HF_TOKEN  # explicitly pass token\n",
    ")\n",
    "\n",
    "print(\"Saved to:\", local_dir)\n",
    "print(\"Zip and download this folder, then point Transformers.js to it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25bb80b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: functiongemma-270m-it/ (stored 0%)\n",
      "updating: functiongemma-270m-it/generation_config.json (deflated 26%)\n",
      "updating: functiongemma-270m-it/model.safetensors (deflated 21%)\n",
      "updating: functiongemma-270m-it/.gitattributes (deflated 86%)\n",
      "updating: functiongemma-270m-it/tokenizer.json (deflated 83%)\n",
      "updating: functiongemma-270m-it/README.md (deflated 64%)\n",
      "updating: functiongemma-270m-it/config.json (deflated 64%)\n",
      "updating: functiongemma-270m-it/tokenizer.model (deflated 52%)\n",
      "updating: functiongemma-270m-it/tokenizer_config.json (deflated 97%)\n",
      "updating: functiongemma-270m-it/added_tokens.json (deflated 19%)\n",
      "updating: functiongemma-270m-it/chat_template.jinja (deflated 84%)\n",
      "updating: functiongemma-270m-it/special_tokens_map.json (deflated 76%)\n",
      "updating: functiongemma-270m-it/tiny_garden.litertlm (deflated 20%)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_c367b332-41e8-4d65-939c-79388d00e4b8\", \"functiongemma-270m-it.zip\", 662911044)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -rf /content/functiongemma-270m-it/.cache\n",
    "!cd /content && zip -r functiongemma-270m-it.zip functiongemma-270m-it\n",
    "from google.colab import files\n",
    "files.download(\"/content/functiongemma-270m-it.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5afe9903",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-796182033.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp /content/functiongemma-270m-it.zip /content/drive/MyDrive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "!cp /content/functiongemma-270m-it.zip /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a52edc",
   "metadata": {},
   "source": [
    "## Use the downloaded folder in Transformers.js\n",
    "\n",
    "After downloading the folder to your machine, set an env var before launching the extension host:\n",
    "\n",
    "\n",
    "\n",
    "- On PowerShell (current session):\n",
    "\n",
    "  ```powershell\n",
    "  $env:GEMMA_MODEL_DIR = \"C:/path/to/functiongemma-270m-it\"\n",
    "  $env:HUGGING_FACE_HUB_TOKEN = \"hf_xxx\"  # optional if using local files only\n",
    "  npm run compile\n",
    "  # then F5 to launch extension\n",
    "  ```\n",
    "\n",
    "- The extension will load from `GEMMA_MODEL_DIR` if set; otherwise it uses the HF repo with `HUGGING_FACE_HUB_TOKEN`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c6156",
   "metadata": {},
   "source": [
    "## Integration with VS Code Extension\n",
    "\n",
    "The VS Code extension now uses this local model instead of the Gemini API. The model runs entirely on the user's machine, providing privacy and avoiding API limits.\n",
    "\n",
    "### Benefits:\n",
    "- No API keys required\n",
    "- Runs locally (privacy)\n",
    "- No usage limits\n",
    "- Works offline\n",
    "\n",
    "### Setup Steps:\n",
    "1. Install @xenova/transformers package\n",
    "2. Load the model on first use\n",
    "3. Use for text generation tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
